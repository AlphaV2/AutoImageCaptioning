# -*- coding: utf-8 -*-
"""AI_IMAGE_CAPTIONING_SYSTEM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17dn1kTTvteSAZiPRPgyLACsRLmWg5JXU
"""

!pip install torch torchvision transformers pillow gradio

import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import gradio as gr

# Load BLIP model
device = "cuda" if torch.cuda.is_available() else "cpu"
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base").to(device)

def generate_caption(image_path):
    image = Image.open(image_path).convert("RGB")
    inputs = processor(images=image, return_tensors="pt").to(device)

    with torch.no_grad():
        output = model.generate(**inputs, max_length=30)

    caption = processor.tokenizer.decode(output[0], skip_special_tokens=True)
    return caption

def upload_and_generate_caption(image):
    caption = generate_caption(image)
    return caption

iface = gr.Interface(
    fn=upload_and_generate_caption,
    inputs=gr.inputs.Image(type="file"),
    outputs="text",
    title="Image Caption Generator",
    description="Upload an image to generate a caption using the BLIP model."
)

if __name__ == "__main__":
    iface.launch()
